import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, classification_report

# ğŸ“Œ 1. Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Ï„Î¿Ï… dataset
df = pd.read_csv("train_dataset.csv")

# ğŸ“Œ 2. Î”Î¹Î±Ï‡Ï‰ÏÎ¹ÏƒÎ¼ÏŒÏ‚ Ï‡Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÏÎ½ ÎºÎ±Î¹ labels
X = df.drop(columns=['slice Type']).values
y = df['slice Type'].values  # ÎšÎ±Ï„Î·Î³Î¿ÏÎ¯ÎµÏ‚ (1, 2, 3)

# ğŸ”¹ Î”Î¹ÏŒÏÎ¸Ï‰ÏƒÎ·: ÎœÎµÏ„Î±Ï„ÏÎ¿Ï€Î® labels ÏÏƒÏ„Îµ Î½Î± Î¾ÎµÎºÎ¹Î½Î¿ÏÎ½ Î±Ï€ÏŒ 0 (0, 1, 2 Î±Î½Ï„Î¯ Î³Î¹Î± 1, 2, 3)
y = y - 1

# ğŸ“Œ 3. ÎšÎ±Î½Î¿Î½Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· Ï„Ï‰Î½ Ï‡Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÏÎ½ (Î±Ï€Î±ÏÎ±Î¯Ï„Î·Ï„Î¿ Î³Î¹Î± XGBoost)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# ğŸ“Œ 4. Î”Î¹Î±Ï‡Ï‰ÏÎ¹ÏƒÎ¼ÏŒÏ‚ ÏƒÎµ train ÎºÎ±Î¹ test sets (80%-20%)
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)

# ğŸ“Œ 5. Î•ÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ· Random Forest Classifier
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)
rf_preds = rf_model.predict(X_test)

# ğŸ“Œ 6. Î•ÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ· XGBoost Classifier
xgb_model = XGBClassifier(n_estimators=100, learning_rate=0.1, random_state=42)
xgb_model.fit(X_train, y_train)
xgb_preds = xgb_model.predict(X_test)

# ğŸ“Œ 7. Î‘Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ· Î‘Ï€ÏŒÎ´Î¿ÏƒÎ·Ï‚
rf_acc = accuracy_score(y_test, rf_preds)
xgb_acc = accuracy_score(y_test, xgb_preds)

print(f"ğŸ¯ Random Forest Accuracy: {rf_acc:.4f}")
print(f"ğŸ¯ XGBoost Accuracy: {xgb_acc:.4f}")

print("\nğŸ”¹ Random Forest Classification Report:")
print(classification_report(y_test, rf_preds))

print("\nğŸ”¹ XGBoost Classification Report:")
print(classification_report(y_test, xgb_preds))
